{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JoCSOy7Gx8JO"
   },
   "source": [
    "# Semantic Segmentation - Automatic Data Augmentation testing and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yQircpmOyBlk"
   },
   "source": [
    "## Setup - Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aVWFJ4I1QV2m"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "from google.colab import files as colab_files\n",
    "drive.mount(\"/content/gdrive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ra9zHaMayJwo"
   },
   "source": [
    "## Setup - Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kwuJtEI3SMe9"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import shutil\n",
    "from matplotlib.pyplot import imshow\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JVmYP48X_P9q"
   },
   "outputs": [],
   "source": [
    "SIZE = 256\n",
    "STRIDE = 64\n",
    "REMOVE_NOTHING_CHANCE = 75 # chance of removing a clear image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rmx_Gypz3kWS"
   },
   "outputs": [],
   "source": [
    "WORK_DIR = \"./project\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yNuID7mwxlpv"
   },
   "source": [
    "## Setup - Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LqDLpCfvxlBA"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/divamgupta/image-segmentation-keras\n",
    "%cd image-segmentation-keras\n",
    "!python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aNp1gXJ1Srr5"
   },
   "outputs": [],
   "source": [
    "import keras_segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E1Z3LpPR43fG"
   },
   "source": [
    "## Setup - Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s3gFH5vb48w9"
   },
   "source": [
    "### Dataset related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tG2yBCQa-GVg"
   },
   "outputs": [],
   "source": [
    "# creates a new dataset folder and a dataset-gen.zip file\n",
    "def develop_dataset():\n",
    "    reset_dataset()\n",
    "    os.system(\"unzip \\\"%s/dataset.zip\\\"\" % (WORK_DIR))\n",
    "    os.system(\"mkdir \\\n",
    "            dataset/train-x dataset/train-y \\\n",
    "            dataset/train-processed \\\n",
    "            out \\\n",
    "            tmp\")\n",
    "    convert_png()\n",
    "    cut_images(STRIDE) # clear_dataset() is already called in here\n",
    "    verify_data()\n",
    "    os.system(\"zip -0 -r dataset-gen.zip dataset/ && \\\n",
    "                mv dataset-gen.zip \\\"%s/\\\"\" % (WORK_DIR))\n",
    "\n",
    "# unzips the generated dataset folder from the dataset-gen zip file\n",
    "def create_dataset():\n",
    "    os.system(\"unzip \\\"%s/dataset-gen.zip\\\"\" % (WORK_DIR))\n",
    "    verify_data()\n",
    "\n",
    "# resets the dataset folder\n",
    "def reset_dataset():\n",
    "    os.system(\"rm -rf dataset\")\n",
    "    create_dataset()\n",
    "\n",
    "def verify_data():\n",
    "    train_x = 0 # train input files quantity\n",
    "    train_p = 0 # train processed files quantity\n",
    "    for file in glob.iglob(\"dataset/train-x/*.png\"):\n",
    "        train_x += 1\n",
    "    for file in glob.iglob(\"dataset/train-processed/*.png\"):\n",
    "        train_p += 1\n",
    "\n",
    "    print(\"[Verify data] train_x\", train_x, \", train_p\", train_p)\n",
    "    if train_x != train_p:\n",
    "        print(\"[ERROR] Dataset input and output quantity isn't synced\")\n",
    "\n",
    "# move the output folder\n",
    "def move_out(folder):\n",
    "    os.rename(\"out\", \"%s/%s\" % (WORK_DIR, folder))\n",
    "\n",
    "# converts all the dataset images from .tif to .png\n",
    "def convert_png():\n",
    "    for file in glob.iglob(\"dataset/*/**.tif\"):\n",
    "        img = cv2.imread(file, 0)\n",
    "        cv2.imwrite(file.replace(\".tif\", \".png\"), img)\n",
    "\n",
    "# clears the dataset (removes some images)\n",
    "def clear_dataset():\n",
    "    for file in glob.iglob(\"dataset/train-y/*.png\"):\n",
    "        img = cv2.imread(file, 0)\n",
    "        if np.sum(img) == 0:\n",
    "            if random.randint(0,100) <= REMOVE_NOTHING_CHANCE:\n",
    "                filename = file.split(\"/\")[-1]\n",
    "                file_x = \"dataset/train-x/\" + filename\n",
    "                file_y = file\n",
    "\n",
    "                os.system(\"rm \\\"%s\\\" \\\"%s\\\"\" % (file_x, file_y))\n",
    "\n",
    "# resets the out folder\n",
    "def reset_out():\n",
    "    if os.path.exists(\"out\"):\n",
    "        shutil.rmtree(\"out\")\n",
    "    if os.path.exists(\"tmp\"):\n",
    "        shutil.rmtree(\"tmp\")\n",
    "    os.mkdir(\"tmp\")\n",
    "    os.mkdir(\"out\")\n",
    "    os.mkdir(\"out/src\")\n",
    "    os.mkdir(\"out/split\")\n",
    "    os.mkdir(\"out/over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eHNm8LXnAyuW"
   },
   "outputs": [],
   "source": [
    "def extend_image(file):\n",
    "    img = cv2.imread(file, 0)\n",
    "    height = len(img)\n",
    "    width = len(img[0])\n",
    "\n",
    "    new_height = math.ceil(height/SIZE) * SIZE\n",
    "    new_width = math.ceil(width/SIZE) * SIZE\n",
    "\n",
    "    img_out = np.zeros((new_height,new_width,1))\n",
    "    \n",
    "    # copies the image\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            img_out[y,x] = img[y,x]\n",
    "    \n",
    "    # expands the right area\n",
    "    for y in range(0, height):\n",
    "        for x in range(width, new_width):\n",
    "            img_out[y,x] = img[y,width-1]\n",
    "    \n",
    "    # expands the bottom area\n",
    "    for y in range(height, new_height):\n",
    "        for x in range(0, width):\n",
    "            img_out[y,x] = img[height-1,x]\n",
    "    \n",
    "    # expands the bottom-right area\n",
    "    for y in range(height, new_height):\n",
    "        for x in range(width, new_width):\n",
    "            img_out[y,x] = img[height-1,width-1]\n",
    "\n",
    "    cv2.imwrite(file, img_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8h1aLgrN7HUB"
   },
   "outputs": [],
   "source": [
    "# it's bugged, may or may not work\n",
    "def _download(folder, download_as=None):\n",
    "    if download_as is None:\n",
    "        download_as = folder\n",
    "    if \"/\" in download_as:\n",
    "        download_as = download_as.split(\"/\")[-1]\n",
    "    \n",
    "    zipped = download_as + \".zip\"\n",
    "    \n",
    "    if os.path.exists(download_as):\n",
    "        shutil.rmtree(download_as)\n",
    "    shutil.copytree(folder, download_as)\n",
    "    os.system(\"zip -0 -r \\\"%s\\\" \\\"%s\\\"\" % (zipped, download_as))\n",
    "\n",
    "    #colab_files.download(zipped)\n",
    "    os.rename(zipped, \"%s/%s\" % (WORK_DIR, zipped))\n",
    "    os.remove(zipped)\n",
    "    shutil.rmtree(download_as)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZdrRpsCJbsI5"
   },
   "outputs": [],
   "source": [
    "def download(folder, download_as=None):\n",
    "    if download_as is None:\n",
    "        download_as = folder\n",
    "    if \"/\" in download_as:\n",
    "        download_as = download_as.split(\"/\")[-1]\n",
    "\n",
    "    if not os.path.exists(\"%s/resultados\" % (WORK_DIR)):\n",
    "        os.mkdir(\"%s/resultados\" % (WORK_DIR))\n",
    "        \n",
    "    dest = \"%s/resultados/%s\" % (WORK_DIR, download_as)\n",
    "    if os.path.exists(download_as):\n",
    "        shutil.rmtree(download_as)\n",
    "    if os.path.exists(dest):\n",
    "        shutil.rmtree(dest)\n",
    "    \n",
    "    shutil.copytree(folder, dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P-vJoO-L4zr6"
   },
   "source": [
    "### Image utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5JMZkKzDqQLE"
   },
   "outputs": [],
   "source": [
    "# cut a single image and output its parts to 'outfolder' \n",
    "def cut_image(file, outfolder, stride=STRIDE):\n",
    "    filename = file.split(\"/\")[-1]\n",
    "    index = 0\n",
    "    img = cv2.imread(file, 0)\n",
    "    height = len(img)\n",
    "    width = len(img[0])\n",
    "    for y in range(0, height, stride):\n",
    "        for x in range(0, width, stride):\n",
    "            img_out = np.zeros((SIZE,SIZE,1))\n",
    "            for i in range(SIZE): # y\n",
    "                for j in range(SIZE): # x\n",
    "                    if i+y < height and j+x < width:\n",
    "                        img_out[i,j] = img[i+y,j+x]\n",
    "            cv2.imwrite(\"%s/%06d_%s\" % (outfolder, index, filename), img_out)\n",
    "            index += 1\n",
    "\n",
    "# returns a noised image\n",
    "def noise(image, var):\n",
    "    row,col,ch = image.shape\n",
    "    mean = 0\n",
    "    gauss = np.random.normal(mean,var,(row,col,ch))\n",
    "    gauss = gauss.reshape(row,col,ch)\n",
    "    noisy = image + gauss\n",
    "\n",
    "    cv2.normalize(noisy, noisy, 0, 255, cv2.NORM_MINMAX, dtype=-1)\n",
    "    noisy = noisy.astype(np.uint8)\n",
    "    return noisy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cZUoO-pz5JTh"
   },
   "source": [
    "### Image core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k1FaN0jPx2_-"
   },
   "outputs": [],
   "source": [
    "def cut_images(stride):\n",
    "    for file_x in glob.iglob(\"dataset/input/*.png\"):\n",
    "        filename = file_x.split(\"/\")[-1]\n",
    "        file_y = \"dataset/label/%s\" % (filename)\n",
    "\n",
    "        extend_image(file_x)\n",
    "        extend_image(file_y)\n",
    "\n",
    "        cut_image(file_x, \"dataset/train-x\")\n",
    "        cut_image(file_y, \"dataset/train-y\")\n",
    "    \n",
    "    for file_x in glob.iglob(\"dataset/test-input/*.png\"):\n",
    "        filename = file_x.split(\"/\")[-1]\n",
    "        file_y = \"dataset/test-label/%s\" % (filename)\n",
    "\n",
    "        extend_image(file_x)\n",
    "        extend_image(file_y)\n",
    "    \n",
    "    clear_dataset()\n",
    "    process_label()\n",
    "\n",
    "def process_label():\n",
    "    for file in glob.iglob(\"dataset/train-y/*.png\"):\n",
    "        filename = file.split(\"/\")[-1]\n",
    "        img = cv2.imread(file, 0)\n",
    "        for i in range(len(img)):\n",
    "            for j in range(len(img[i])):\n",
    "                if(img[i,j] > 0): img[i,j] = 1\n",
    "                else: img[i,j] = 0\n",
    "\n",
    "        cv2.imwrite(\"dataset/train-processed/\"+filename, img)\n",
    "\n",
    "# returns float iou score for a single test file\n",
    "def get_iou(filename):\n",
    "    file_out = \"out/src/out_%s\" % (filename)\n",
    "    file_target = \"dataset/test-label/%s\" % (filename)\n",
    "\n",
    "    if not os.path.isfile(file_out):\n",
    "        print(\"[Error/IOU Score] Out file not found\")\n",
    "        return -1\n",
    "    if not os.path.isfile(file_target):\n",
    "        print(\"[Error/IOU Score] Target file not found\")\n",
    "        return -1\n",
    "\n",
    "    out = cv2.imread(file_out, 0)\n",
    "    target = cv2.imread(file_target, 0)\n",
    "\n",
    "    # Evaluates the intersection \"area\"\n",
    "    intersect = 0\n",
    "    for i in range(len(target)):\n",
    "        for j in range(len(target[i])):\n",
    "            if(out[i,j] == 255 and target[i,j] == 255):\n",
    "                intersect += 1\n",
    "    \n",
    "    # Evaluates the union \"area\"\n",
    "    union = 0\n",
    "    for i in range(len(target)):\n",
    "        for j in range(len(target[i])):\n",
    "            if(out[i,j] == 255 or target[i,j] == 255):\n",
    "                union += 1\n",
    "\n",
    "    if union == 0:\n",
    "        union += 1\n",
    "        intersect += 1\n",
    "\n",
    "    iou_score = intersect/union\n",
    "    return iou_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FNQ1xFLD5VQK"
   },
   "source": [
    "### Data Augmentation core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pouM76Sb5RUO"
   },
   "outputs": [],
   "source": [
    "def invert_images(folder):\n",
    "    for file in glob.iglob(\"%s/*\" % (folder)):\n",
    "        img = cv2.imread(file, 0)\n",
    "        for i in range(len(img)):\n",
    "            for j in range(len(img[i])):\n",
    "                img[i,j] = abs(255-img[i,j])\n",
    "        cv2.imwrite(file, img)\n",
    "\n",
    "def normalize_images(folder):\n",
    "    for file in glob.iglob(\"%s/*\" % (folder)):\n",
    "        img = cv2.imread(file)\n",
    "        cv2.normalize(img, img, 0, 255, cv2.NORM_MINMAX, dtype=-1)\n",
    "        cv2.imwrite(file, img)\n",
    "\n",
    "def noise_images(folder, chance, var=5):\n",
    "    for file in glob.iglob(\"%s/*\" % (folder)):\n",
    "        if random.randint(0,100) > chance: continue\n",
    "        img = cv2.imread(file)\n",
    "        img = noise(img, var)\n",
    "        cv2.imwrite(file, img)\n",
    "\n",
    "def flip_images(chance):\n",
    "    for file_x in glob.iglob(\"dataset/train-x/*.png\"):\n",
    "        if random.randint(0,100) > chance: continue\n",
    "        file_y = file_x.replace(\"train-x\", \"train-processed\")\n",
    "        \n",
    "        img = cv2.imread(file_x)\n",
    "        img = cv2.flip(img, 0)\n",
    "        cv2.imwrite(file_x.replace(\".png\", \"fp.png\"), img)\n",
    "\n",
    "        img = cv2.imread(file_y)\n",
    "        img = cv2.flip(img, 0)\n",
    "        cv2.imwrite(file_y.replace(\".png\", \"fp.png\"), img)\n",
    "        \n",
    "\n",
    "def rotate_images(chance):\n",
    "    for file_x in glob.iglob(\"dataset/train-x/*.png\"):\n",
    "        if random.randint(0,100) > chance: continue\n",
    "        file_y = file_x.replace(\"train-x\", \"train-processed\")\n",
    "        \n",
    "        img = cv2.imread(file_x)\n",
    "        img = np.rot90(img)\n",
    "        img = np.rot90(img)\n",
    "        cv2.imwrite(file_x.replace(\".png\", \"fp.png\"), img)\n",
    "\n",
    "        img = cv2.imread(file_y)\n",
    "        img = np.rot90(img)\n",
    "        img = np.rot90(img)\n",
    "        cv2.imwrite(file_y.replace(\".png\", \"fp.png\"), img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jofqi9Cr8zbj"
   },
   "source": [
    "## Setup - Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ndZWL0MC5ema"
   },
   "source": [
    "### Model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7sKcEJPJCTS1"
   },
   "outputs": [],
   "source": [
    "def test_model():\n",
    "    reset_out()\n",
    "    \n",
    "    for file in glob.iglob(\"dataset/test-input/*.png\"):\n",
    "        cut_image(file, \"tmp\", stride=SIZE)\n",
    "        filename = file.split(\"/\")[-1]\n",
    "        img_original = cv2.imread(file, 0)\n",
    "        break_width = math.ceil(len(img_original[0])/SIZE) # ceil because there's a padding at the left of the cropped image\n",
    "\n",
    "        img_in = None\n",
    "        img_in_x = None\n",
    "        img_out = None\n",
    "        img_out_x = None\n",
    "        current_width = 0\n",
    "        for file_in in sorted(glob.iglob(\"tmp/*\")):\n",
    "            model.predict_segmentation(\n",
    "                inp=file_in,\n",
    "                out_fname=\"tmp_out.png\"\n",
    "            )\n",
    "            temp_in = cv2.imread(file_in, 0)\n",
    "            temp_out = cv2.imread(\"tmp_out.png\", 0)\n",
    "\n",
    "            if img_out_x is None:\n",
    "                img_out_x = temp_out\n",
    "                img_in_x = temp_in\n",
    "            else:\n",
    "                img_out_x = np.append(img_out_x, temp_out, axis=1)\n",
    "                img_in_x = np.append(img_in_x, temp_in, axis=1)\n",
    "\n",
    "            current_width += 1\n",
    "\n",
    "            if current_width == break_width:\n",
    "                if img_out is None:\n",
    "                    img_out = img_out_x\n",
    "                    img_in = img_in_x\n",
    "                else:\n",
    "                    img_out = np.append(img_out, img_out_x, axis=0)\n",
    "                    img_in = np.append(img_in, img_in_x, axis=0)\n",
    "                img_out_x = None\n",
    "                img_in_x = None\n",
    "                current_width = 0\n",
    "        \n",
    "        for i in range(len(img_out)):\n",
    "            for j in range(len(img_out[i])):\n",
    "                if(img_out[i,j] > 200): img_out[i,j] = 255\n",
    "                else: img_out[i,j] = 0\n",
    "            \n",
    "        os.system(\"rm tmp/*\")\n",
    "\n",
    "        cv2.imwrite(\"out/src/out_%s\" % (filename), img_out)\n",
    "        cv2.imwrite(\"out/src/in_%s\" % (filename), img_in)\n",
    "\n",
    "        process_out(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kydu80eQH7pW"
   },
   "outputs": [],
   "source": [
    "def process_out(file):\n",
    "    img_in = cv2.imread(\"out/src/in_%s\" % (file), 1)\n",
    "    img_out = cv2.imread(\"out/src/out_%s\" % (file), 1)\n",
    "    img_target = cv2.imread(\"dataset/test-label/%s\" % (file), 1)\n",
    "    \n",
    "    # Gets the iou score\n",
    "    iou_score = get_iou(file)\n",
    "    if iou_score == -1:\n",
    "        print(\"Error while checking iou_score\")\n",
    "        return\n",
    "    \n",
    "    # Creates/appends the description file\n",
    "    create_header = False\n",
    "    if not os.path.isfile(\"out/description.csv\"):\n",
    "        create_header = True\n",
    "    with open(\"out/description.csv\", \"a\") as desc:\n",
    "        if create_header:\n",
    "            desc.write(\"name,iou\\n\")\n",
    "        desc.write(\"%s,%f\\n\" % (file, iou_score))\n",
    "\n",
    "    # Creates the \"splitscreen\" image\n",
    "    img = np.append(img_in, img_out, axis=1)\n",
    "    cv2.imwrite(\"out/split/%s\" % (file), img)\n",
    "\n",
    "    # Creates the overlayed image (in and out)\n",
    "    for i in range(len(img_out)):\n",
    "        for j in range(len(img_out[i])):\n",
    "            if img_out[i,j][0] == 255:\n",
    "                img_out[i,j] = [0, 0, 255] # B,G,R\n",
    "    img = cv2.addWeighted(img_in,1.0,img_out,0.2,0)\n",
    "    cv2.imwrite(\"out/%s\" % (file), img)\n",
    "\n",
    "    # Creates the overlayed image (out and target)\n",
    "    img = cv2.addWeighted(img_target,0.85,img_out,0.7,0)\n",
    "    cv2.imwrite(\"out/over/%s\" % (file), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CKE2odZa82sE"
   },
   "outputs": [],
   "source": [
    "model = keras_segmentation.models.segnet.segnet(n_classes=2, input_height=SIZE, input_width=SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BhI-45eF8NGz"
   },
   "outputs": [],
   "source": [
    "def reset_all():\n",
    "    model = keras_segmentation.models.segnet.segnet(n_classes=2, input_height=SIZE, input_width=SIZE)\n",
    "    reset_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dWgvNl7W8g8c"
   },
   "outputs": [],
   "source": [
    "def log_out(texts):\n",
    "    with open(\"out/description.txt\", \"w\") as file:\n",
    "        file.write(\"\\n\".join(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EamrL3Gmv9Vl"
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train( \n",
    "        train_images =  \"dataset/train-x/\",\n",
    "        train_annotations = \"dataset/train-processed/\",\n",
    "        checkpoints_path = \"%s/model/model-ckpt.h5\" % (WORK_DIR) , epochs=50\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EVDSqTuZm5gV"
   },
   "outputs": [],
   "source": [
    "def fetch_model_results():\n",
    "    results_folder = \"%s/resultados\" % (WORK_DIR)\n",
    "    model_file = \"%s/model.csv\" % (WORK_DIR)\n",
    "\n",
    "    if not os.path.isfile(model_file):\n",
    "        with open(model_file, \"w\") as file:\n",
    "            file.write(\"name,iou,augmentations\\n\")\n",
    "\n",
    "    def get_file_lines(file_name):\n",
    "        lines = []\n",
    "        with open(file_name, \"r\") as file:\n",
    "            lines = file.readlines()\n",
    "        for i in range(len(lines)):\n",
    "            lines[i] = lines[i].replace(\"\\n\",\"\")\n",
    "        return lines\n",
    "\n",
    "    for root, dirs, files in os.walk(results_folder, topdown = False):\n",
    "        for name in files:\n",
    "            if name == \"description.csv\":\n",
    "                path = os.path.join(root, name)\n",
    "                \n",
    "                csv_file = os.path.join(root, name)\n",
    "                txt_file = os.path.join(root, \"description.txt\")\n",
    "\n",
    "                # get the augmentations\n",
    "                txt_lines = get_file_lines(txt_file)\n",
    "                augmentations = \"/\".join(txt_lines)\n",
    "\n",
    "                # get the csv lines from training and append them with the augmentations\n",
    "                csv_lines = get_file_lines(csv_file)\n",
    "                csv_lines.pop(0)\n",
    "                for i in range(len(csv_lines)):\n",
    "                    csv_lines[i] = csv_lines[i] + \",\" + augmentations\n",
    "                \n",
    "                # write the results to the main model csv file\n",
    "                with open(model_file, \"a\") as file:\n",
    "                    for l in csv_lines:\n",
    "                        file.write(l + \"\\n\")\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vLIkpiWu85Zs"
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HV3-WKbM9Z_S"
   },
   "source": [
    "### Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6R_9anaW8-45"
   },
   "outputs": [],
   "source": [
    "create_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "44LQN-qJ9ban"
   },
   "source": [
    "### Processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BrNSk2vvrf1B"
   },
   "outputs": [],
   "source": [
    "reset_dataset()\n",
    "train()\n",
    "test_model()\n",
    "log_out([\"limpo\"])\n",
    "download(\"out\", \"limpo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x6jLmKb38GWZ"
   },
   "outputs": [],
   "source": [
    "reset_all()\n",
    "normalize_images(\"dataset/train-x\")\n",
    "normalize_images(\"dataset/test-input\")\n",
    "train()\n",
    "test_model()\n",
    "log_out([\"normalizado\"])\n",
    "download(\"out\", \"normalizado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IlQgXx5DalAa"
   },
   "outputs": [],
   "source": [
    "reset_all()\n",
    "normalize_images(\"dataset/test-input\")\n",
    "train()\n",
    "test_model()\n",
    "log_out([\"teste_normalizado\"])\n",
    "download(\"out\", \"teste_normalizado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2NxKV_CLVAFo"
   },
   "outputs": [],
   "source": [
    "reset_all()\n",
    "noise_images(\"dataset/train-x\", 50, var=5)\n",
    "train()\n",
    "test_model()\n",
    "log_out([\"ruido 50% σ²=5\"])\n",
    "download(\"out\", \"ruido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZGHiguDnSmLi"
   },
   "outputs": [],
   "source": [
    "reset_all()\n",
    "normalize_images(\"dataset/train-x\")\n",
    "normalize_images(\"dataset/test-input\")\n",
    "noise_images(\"dataset/train-x\", 50, var=5)\n",
    "train()\n",
    "test_model()\n",
    "log_out([\"normalizado\", \"ruido 50% σ²=5\"])\n",
    "download(\"out\", \"normalizado ruido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "trdO5aL9PGw4"
   },
   "outputs": [],
   "source": [
    "reset_all()\n",
    "normalize_images(\"dataset/train-x\")\n",
    "normalize_images(\"dataset/test-input\")\n",
    "noise_images(\"dataset/train-x\", 50, var=12)\n",
    "train()\n",
    "test_model()\n",
    "log_out([\"normalizado\", \"ruido 50% σ²=12\"])\n",
    "download(\"out\", \"normalizado ruido12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fenTB4McTkIf"
   },
   "outputs": [],
   "source": [
    "reset_all()\n",
    "normalize_images(\"dataset/train-x\")\n",
    "normalize_images(\"dataset/test-input\")\n",
    "flip_images(50)\n",
    "train()\n",
    "test_model()\n",
    "log_out([\"normalizado\", \"espelhado 50%\"])\n",
    "download(\"out\", \"normalizado espelhado50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1jrSu0g6AJVD"
   },
   "outputs": [],
   "source": [
    "reset_all()\n",
    "normalize_images(\"dataset/train-x\")\n",
    "normalize_images(\"dataset/test-input\")\n",
    "flip_images(100)\n",
    "train()\n",
    "test_model()\n",
    "log_out([\"normalizado\", \"espelhado 100%\"])\n",
    "download(\"out\", \"norm espelhado100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "16AAhHK_91OB"
   },
   "outputs": [],
   "source": [
    "reset_all()\n",
    "normalize_images(\"dataset/train-x\")\n",
    "normalize_images(\"dataset/test-input\")\n",
    "flip_images(50)\n",
    "invert_images(\"dataset/train-x\")\n",
    "invert_images(\"dataset/test-input\")\n",
    "train()\n",
    "test_model()\n",
    "log_out([\"normalizado\", \"espelhado 50%\", \"invertido\"])\n",
    "download(\"out\", \"normalizado espelhado invertido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j0uM_pEpTknN"
   },
   "outputs": [],
   "source": [
    "reset_all()\n",
    "normalize_images(\"dataset/train-x\")\n",
    "normalize_images(\"dataset/test-input\")\n",
    "flip_images(50)\n",
    "noise_images(\"dataset/train-x\", 50, var=5)\n",
    "train()\n",
    "test_model()\n",
    "log_out([\"normalizado\", \"espelhado 50%\", \"ruido σ²=5\"])\n",
    "download(\"out\", \"normalizado espelhado ruido5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "va0DZrFVZAUN"
   },
   "outputs": [],
   "source": [
    "reset_all()\n",
    "normalize_images(\"dataset/train-x\")\n",
    "normalize_images(\"dataset/test-input\")\n",
    "flip_images(50)\n",
    "noise_images(\"dataset/train-x\", 50, var=3)\n",
    "train()\n",
    "test_model()\n",
    "log_out([\"normalizado\", \"espelhado 50%\", \"ruido σ²=3\"])\n",
    "download(\"out\", \"normalizado espelhado ruido3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NgRZqR47jTcN"
   },
   "outputs": [],
   "source": [
    "reset_all()\n",
    "rotate_images(50)\n",
    "flip_images(20)\n",
    "noise_images(\"dataset/train-x\", 50, var=5)\n",
    "normalize_images(\"dataset/train-x\")\n",
    "normalize_images(\"dataset/test-input\")\n",
    "train()\n",
    "test_model()\n",
    "log_out([\"tudo\"])\n",
    "download(\"out\", \"tudo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nhkfd8zKyWCH"
   },
   "outputs": [],
   "source": [
    "fetch_model_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UNTEMym_NQv9"
   },
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JWL2spERNQEb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4qVYV2y4NXbN"
   },
   "outputs": [],
   "source": [
    "models_csv_paths = [\"model1.csv\"]\n",
    "titles = [\"SegNet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fce1d8_1NpLs"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(models_csv_paths[0])\n",
    "augs = []\n",
    "for x in df['augmentations']:\n",
    "    if x not in augs:\n",
    "        augs.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e4cRvFpQ2mnt"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=len(augs), ncols=len(models_csv_paths), sharey='all', figsize=(3.5*len(models_csv_paths), 2.5*(len(augs))))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MnAaQfzy2r_R"
   },
   "outputs": [],
   "source": [
    "for modelid, csv_file in enumerate(models_csv_paths):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df = df.sort_values('name')\n",
    "    \n",
    "    for i, a in enumerate(augs):\n",
    "        iou_scores = df.loc[df['augmentations'] == a]['iou']\n",
    "        iou_scores = iou_scores.values\n",
    "\n",
    "        title = \"\"\n",
    "        x = np.arange(1,len(iou_scores)+1)\n",
    "        y = iou_scores\n",
    "\n",
    "        for j in range(len(iou_scores)):\n",
    "            if y[j] == 0:\n",
    "                if len(models_csv_paths) == 1: ax[i].scatter(x[j], y[j], color='red')\n",
    "                else: ax[i, modelid].scatter(x[j], y[j], color='red')\n",
    "            else:\n",
    "                if len(models_csv_paths) == 1: ax[i].scatter(x[j], y[j], color='blue')\n",
    "                else: ax[i, modelid].scatter(x[j], y[j], color='blue')\n",
    "        if i == 0:\n",
    "            for t in titles[modelid].split(\" \"):\n",
    "                title += r\"$\\bf{\" + t + \"}$ \"\n",
    "            title = title + \"\\n\\n\" + a.replace(\"_\", \" \")\n",
    "            \n",
    "        else:\n",
    "            title = a.replace(\"_\", \" \")\n",
    "        \n",
    "        if len(models_csv_paths) == 1:\n",
    "            ax[i].set_title(title)\n",
    "\n",
    "            ax[i].set_xlabel(\"Número da imagem\")\n",
    "            ax[i].set_ylabel(\"iou score\")\n",
    "        else:\n",
    "            ax[i, modelid].set_title(title)\n",
    "\n",
    "            ax[i, modelid].set_xlabel(\"Número da imagem\")\n",
    "            ax[i, modelid].set_ylabel(\"iou score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gl1uvyES2_Mk"
   },
   "outputs": [],
   "source": [
    "fig.tight_layout()\n",
    "fig.subplots_adjust(hspace=0.7)\n",
    "fig.savefig(\"%s/out.png\" % (WORK_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GsCNkPGR26Ms"
   },
   "source": [
    "###"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "segnet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
